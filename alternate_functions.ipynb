{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternate functions that could be used in menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import*\n",
    "import py4j\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .config(\"spark.jars\", \"/Users/nahidrahman/opt/miniconda3/lib/python3.9/site-packages/pyspark/jars/mysql-connector-j-8.0.31.jar\")\\\n",
    "    .appName(\"menu\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_branch = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost:3306/creditcard_capstone\") \\\n",
    "    .option(\"dbtable\", \"CDW_SAPP_BRANCH\") \\\n",
    "    .option(\"user\", \"root\") \\\n",
    "    .option(\"password\", \"password\") \\\n",
    "    .load()\n",
    "\n",
    "df_credit = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost:3306/creditcard_capstone\") \\\n",
    "    .option(\"dbtable\", \"CDW_SAPP_CREDIT\") \\\n",
    "    .option(\"user\", \"root\") \\\n",
    "    .option(\"password\", \"password\") \\\n",
    "    .load()\n",
    "\n",
    "df_custmer = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost:3306/creditcard_capstone\") \\\n",
    "    .option(\"dbtable\", \"CDW_SAPP_CUSTMER\") \\\n",
    "    .option(\"user\", \"root\") \\\n",
    "    .option(\"password\", \"password\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+--------+---+-----+--------------+----------------+-----------------+----+------+------+--------------+---------+------------+----------+----------+----------+--------+----------+---------+------------+-----------+---+-----------+\n",
      "|BRANCH_CODE|CREDIT_CARD_NO|CUST_SSN|DAY|MONTH|TRANSACTION_ID|TRANSACTION_TYPE|TRANSACTION_VALUE|YEAR|TIMEID|APT_NO|CREDIT_CARD_NO|CUST_CITY|CUST_COUNTRY|CUST_EMAIL|CUST_PHONE|CUST_STATE|CUST_ZIP|FIRST_NAME|LAST_NAME|LAST_UPDATED|MIDDLE_NAME|SSN|STREET_NAME|\n",
      "+-----------+--------------+--------+---+-----+--------------+----------------+-----------------+----+------+------+--------------+---------+------------+----------+----------+----------+--------+----------+---------+------------+-----------+---+-----------+\n",
      "+-----------+--------------+--------+---+-----+--------------+----------------+-----------------+----+------+------+--------------+---------+------------+----------+----------+----------+--------+----------+---------+------------+-----------+---+-----------+\n",
      "\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "year = input(\"Choose the year:\")\n",
    "month = input(\"Choose the month:\")\n",
    "zipcode = input(\"Choose zipcode:\")\n",
    "#function that displays the transactions made by customers living in a given zip code for a given month and year, in descending order.\n",
    "def transactions(year, month, zipcode):\n",
    "    df = df_credit.join(df_custmer, df_credit.CUST_SSN == df_custmer.SSN,  'outer')\n",
    "    df.filter( (df['year'] == year) & (df['month'] == month) & (df['CUST_ZIP'] == zipcode)).sort('day', ascending= False).show(10)        \n",
    "transactions(year, month, zipcode)\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gas\n",
      "Entertainment\n",
      "Healthcare\n",
      "Grocery\n",
      "Test\n",
      "Education\n",
      "...\n",
      "The number of Gas transactions is 6605\n",
      "The value of these transactions is $336059.26\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "print (\"Gas\\nEntertainment\\nHealthcare\\nGrocery\\nTest\\nEducation\")\n",
    "types = input(\"Enter one of the following transaction types above: \") \n",
    "print('...')\n",
    "\n",
    "#function that displays the number and total values of transactions for a given type.\n",
    "#Used credit pyspark dataframe and filtered based on transaction type. To get the total values, used the group by and sum method.\n",
    "def total_transactions(type):\n",
    "    transactions_of_type = df_credit.filter(df_credit['transaction_type'] == type).count()\n",
    "    print(f'The number of {type} transactions is {transactions_of_type}')\n",
    "    \n",
    "    value_of_transaction_type = df_credit.filter(df_credit['transaction_type'] == type).groupBy().sum('transaction_value')\n",
    "    formatted_total_value = value_of_transaction_type.select(round(value_of_transaction_type[0], 2)).collect()[0][0]\n",
    "\n",
    "    print(f\"The value of these transactions is ${formatted_total_value}\")\n",
    "\n",
    "total_transactions(types)\n",
    "print(\"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "The number of transactions in NY is 4143\n",
      "The value of these transactions is $213717.38\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "state = input(\"Enter a state (abbreviation): \")\n",
    "print('...')\n",
    "\n",
    "def branch_transactions(state):\n",
    "    df2 = df_credit.join(df_branch, df_credit.BRANCH_CODE == df_branch.BRANCH_CODE, 'outer')\n",
    "    transactions_in_state = df2.filter(df2['BRANCH_STATE'] == state).count()\n",
    "    print(f\"The number of transactions in {state} is {transactions_in_state}\")\n",
    "    value_of_transactions = df2.filter(df2['BRANCH_STATE'] == state).groupBy().sum('transaction_value')\n",
    "    formatted_total_value = value_of_transactions.select(round(value_of_transactions[0], 2)).collect()[0][0]\n",
    "    print(f\"The value of these transactions is ${formatted_total_value}\")\n",
    "\n",
    "branch_transactions(state)\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------+------------+----------+----------+----------+--------+----------+---------+------------+-----------+---+-----------+\n",
      "|APT_NO|CREDIT_CARD_NO|CUST_CITY|CUST_COUNTRY|CUST_EMAIL|CUST_PHONE|CUST_STATE|CUST_ZIP|FIRST_NAME|LAST_NAME|LAST_UPDATED|MIDDLE_NAME|SSN|STREET_NAME|\n",
      "+------+--------------+---------+------------+----------+----------+----------+--------+----------+---------+------------+-----------+---+-----------+\n",
      "+------+--------------+---------+------------+----------+----------+----------+--------+----------+---------+------------+-----------+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SSN = input(\"Enter your SSN:\")\n",
    "\n",
    "#function that views the existing account details of a customer given SSN.\n",
    "def account_details(SSN):\n",
    "    df_custmer.filter(df_custmer['SSN'] == SSN).show()\n",
    "account_details(SSN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "credit_card_no = input(\"Enter your credit card number: \")\n",
    "month = input(\"Enter a month: \")\n",
    "year = input(\"Enter a year: \")\n",
    "\n",
    "# Function that generates a monthly bill for a credit card number for a given month and year.\n",
    "import calendar\n",
    "\n",
    "def monthly_bill(credit_card_no, month, year):\n",
    "    month = int(month)\n",
    "    \n",
    "    if 1 <= month <= 12:\n",
    "        bill = df_credit.filter(\n",
    "            (df_credit['credit_card_no'] == credit_card_no) &\n",
    "            (df_credit['month'] == month) &\n",
    "            (df_credit['year'] == year)\n",
    "        ).toPandas()\n",
    "\n",
    "        bill_sum = bill['TRANSACTION_VALUE'].sum()\n",
    "\n",
    "        month_name = calendar.month_name[month]\n",
    "\n",
    "        # Don't use PySpark's round function here\n",
    "        formatted_bill_sum = round(bill_sum, 2)\n",
    "\n",
    "        print(f\"The monthly bill for {month_name} is ${formatted_bill_sum}\")\n",
    "    else:\n",
    "        print(\"Invalid month. Please enter a month between 1 and 12.\")\n",
    "\n",
    "monthly_bill(credit_card_no, month, year)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
